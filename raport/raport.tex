\documentclass[11pt, a4wide]{article}

\usepackage{polski}
\usepackage{a4wide}
\usepackage[utf8]{inputenc}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{algorithmicx}
\usepackage{algpseudocode}


\title{Algorytm ewolucyjny dla problemu flow shop}
\author{Jan Sochiera \and Krzysztof Chrobak}

\begin{document}
\maketitle
\newpage

\section{Wstęp}


\section{Problem}
\subsection{Definicja}
Problem flow shop jest NP-trudną odmianą problemu szeregowania $n$ zadań na $m$ maszynach, w której:
\begin{itemize}
  \item każde zadanie musi zostać wykonane na każdej maszynie
  \item kolejność wykonywania zadań na wszystkich maszynach jest taka sama
  \item zadanie może być wykonywane jednocześnie na tylko jednej maszynie
\end{itemize}
Ten abstrakcyjny opis pasuje do wielu rzeczywistych zagadnień, np. linii montażowej w 
fabryce, na której przetwarzane przedmioty przechodzą przez poszczególne etapy produkcji w tej
samej kolejności, choć czas który w nich spędzają może się znacząco różnić.

Problem jest w całości definiowany przez następujące dane:
\begin{itemize}
  \item $n$ - ilość zadań
  \item $m$ - ilość maszyn 
  \item macierz $T$, w której $T_{ij}$ to czas przetwarania $j$-tego zadania na $i$-tej maszynie
\end{itemize}

\subsection{Przestrzeń przeszukiwań}
Łatwo zauważyć, że przebieg całego procesu odpowiadającego danej instancji problemu flow shop
jest w całości zdefiniowany przez kolejność zadań na pierwszej maszynie, ponieważ na każdej innej
zadania będą wykonywane dokładnie w tym samym porządku. Wynika z tąd, że przestrzenią poszukiwań jest
$S_n$ : zbiór wszystkich permutacji zbioru $n$ elementowego. Oczywiście $|S_n| = n!$, więc dla $n>10$
przeszukanie całej przestrzeni staje się niepraktyczne.

\subsection{Funkcja celu}
W naszym projekcie przyjeliśmy, że funkcją celu będzie  $ makespan : S_n \rightarrow \mathbb{R} $, który
definiujemy jako czas od rozpoczęcia wykonywania pierwszego zadania na pierwszej maszynie do 
zakończenia wykonywania ostatniego zadania na ostatniej maszynie.

\subsection{Rozkład wartości $makespan(\pi)$}
Dla instancji problemu, gdzie $n$ jest duże przestrzeń przeszukiwań jest tak ogromna, że trudno
cokolwiek powiedzieć o rozkładzie wartości $makespan$, dlatego postanowiliśmy sprawdzić jak ta funkcja
zachowuje się dla $n = 10$, gdzie możliwe jest policzenie jej wartości dla każdego $\pi \in S_n$.
W naszym eksperymencie przyjeliśmy $m = TODO$, a $T_{ij}$ wylosowaliśmy z rozkładem jednostajnym 
z przedziału $[10, 20]$. Powtórzyliśmy eksperyment 30 razy i sporządziliśmy histogram otrzymanych
wyników, który można zobaczyć na wykresie 1 TODO;




\section{Algorytm}
Algorytm który zaimplementowaliśmy jest modyfikacją klasycznego SGA, do której dodaliśmy przeszukiwanie lokalne
i zwiększanie różnorodności populacji poprzez dodawanie losowych imigrantów. Dane wejściowe dla tego algorytmu:
\begin{description}
  \item[instance] instancja problemu flow shop
  \item[population\_size] rozmiar populacji
  \item[num\_parents] ilość rodziców
  \item[mutation\_probability] prawdopodobieństwo mutacji
  \item[$\alpha$] parametr imigracji
\end{description}
Pseudokod:

\begin{algorithmic}
  \State $P \gets RandomPopulation(population\_size)$
  \State $EvaluatePopulation(P, instance)$
  \While{not $TerminationCondition(P)$}
    \State $Parents \gets SelectParents(P, num\_parents)$ 
    \State $Children \gets Crossover(Parents)$
    \State $Children \gets Mutate(Children, mutation\_probability)$
    \State $Children \gets LocalSearch(Children, instance)$
    \State $Population \gets Replace(Population, Children)$
    \State $Population \gets AddImigrants(Population, instance, \alpha)$
  \EndWhile
\end{algorithmic}

\subsection{Ocena osobników $EvaluatePopulation$}
Pojedyńczego osobnika można ocenić przy pomocy prostego algorytmu dynamicznego, korzystającego
z następujących zależności ($E[i,j]$ to czas zakończenia wykonywania $j$-tego w kolejności zadania
na $i$-tej maszynie, przy kolejności zadań $\pi$):
$$ E[1, 1] = t_{1,\pi(1)} $$
$$ E[1, i] = E[1, i-1] + t_{1,\pi(i)}\ \  i = 2 \ldots n$$
$$ E[i, 1] = E[i-1, 1] + t_{i,\pi(1)}\ \  i = 2 \ldots m$$
$$ E[i, j] = max(E[i-1, j], E[i, j-1]) + t_{i, \pi(j)} \ \ i = 2 \ldots n \ \ j = 2 \ldots m $$
Algorytm dynamiczny oceny jednego osobnika ma złożoność $O(nm)$

\subsection{Warunek zakończenia $TerminationCondition$}
Nasz algorytm kończy działanie gdy przekroczy ustaloną z góry ilość iteracji pętli while, albo
gdy uda mu się osiągnąć wartość funkcji celu znaną jako optymalna dla danego problemu. Oczywiście
ten ostatni warunek należałoby usunąć chcąc rozwiązywać nowe problemy, ale podczas testowania 
algorytmu szukanie rozwiązania lepszego niż optymalne nie miało żadnego sensu.

\subsection{Wybór rodziców $SelectParents$}
Eksperymentowaliśmy z dwiema metodami wyboru rodziców:
\begin{itemize}
  \item Metoda ruletki z różnymi skalowaniami funkcji przystosowania
  \item Metoda k-najlepszych osobników
\end{itemize}
W ostatecznej wersji algorytmu zdecydowaliśmy się na drugą metodę, ponieważ
w połączeniu z metodą ruletki nie dało się stosować wybranej przez nas strategii zastępowania. Okazało 
się również, że warto pozwalać wszystkim osobnikom wziąć udział w reprodukcji.

\subsection{Krzyżowanie $Crossover$}
Osobniki wybrane do reprodukcji są losowo kojarzone w pary, tak że każdy ma dokładnie jednego partnera.
Do krzyżowania użylismy prostego operatora PMX.

\subsection{Mutacja $Mutate$}
Z pewnym małym prawdopodobieństwem (po kilku eksperymentach ustaliliśmy tą wartość na 5\%) każde dziecko jest
mutowane. Mutacja polega na złożeniu permutacji osobnika z losową permutacją o około 75\% punktów stałych.

\subsection{Przeszukiwanie lokalne $LocalSearch$}
Ten krok algorytmu ma kluczowe znaczenie dla jakości otrzymywanych rozwiązań, ponieważ jeśli za bardzo przyspieszy
zbieżność, to algorytm będzie miał tendencję do utykania w minimach lokalnych, a jeśli będzie go brakowało, 
to ewolucja nie będzie w stanie w rozsądnym czasie znaleźć dobrego rozwiązania. Czas obliczania tego kroku
decyduje też o czasie działania całego algorytmu, bo polega on na przeszukaniu pewnego otoczenia osobnika
w poszukiwaniu lepszego niż on sam sąsiada. Zdecydowaliśmy się na następujący schemat przeszukiwania lokalnego:
\begin{algorithmic}
  \For {$i \gets 1 \ldots |Children|$}
    \State $I \gets Children[i]$
    \State $best \gets I$
    \State $mspan \gets makespan(I)$
    \For {$j \gets 1 \ldots n$}
      \For {$k \gets 1 \ldots n$}
        \State $Candidate \gets insert(I, i, k)$
        \State $cspan \gets makespan(Candidate)$
        \If{$cspan < mspan $}
          \State $mspan \gets cspan$
          \State $best \gets Candidate$
        \EndIf
      \EndFor
    \EndFor
    \State $Children[i] = best$
  \EndFor
\end{algorithmic}
Czyli mówiąc krótko dla każdego dziecka próbujemy włożyć $j$-te zadanie na $k$-tą pozycję dla 
wszystkich sensownych $j$ i $k$. Złożoność obliczeniowa takiego podejścia przy zastosowaniu algorytmu
oceny przytoczonego wcześniej to $O(n^3k|Children|)$, ale przy zastosowaniu sprytniejszego algorytmu
z pracy \cite{tai90}, można ją zredukować do $O(n^2k|Children|)$.

\subsection{Zastępowanie $Replace$}
Aby uniemożliwić najlepszym osobnikom zdominowanie populacji po kilku iteracjach, użyliśmy schematu
zastępowania, który bierze pod uwagę tylko czwórkę osobników : parę rodziców i ich dzieci. Z takiej
czwórki wybieramy 2 najlepszych osobników, i to oni przechodzą do następnego pokolenia. Oczywiście
tą procedurę należy powtórzyć dla wszystkich par rodziców wygenerowanych w kroku krzyżowania.

\subsection{Imigracja $AddImigrants$}
Aby algorytm działał dowolnie długo, postanowiliśmy mierzyć różnorodność osobników w populacji i w razie jej
spadku zastępować najgorsze osobniki losowymi. Wprowadziliśmy współczynnik różnorodności $D$:
$$ D = \frac{\text{ilość różnych osobników}}{\text{ilość osobników}} $$
Ilość osobników zastępowanych losowymi jest określona przez parametr $\alpha$ i zależność:
$$ N_{random} = \lfloor \alpha * (1 - D) * population\_size  \rfloor $$
Aby nowe osobniki nie zostały wyeliminowane po jednej iteracji, wykonujemy dla każdego z nich przeszukiwanie
lokalne.




\section{Implementacja}
Algorytm zaimplementowaliśmy w C++ przy użyciu biblioteki OpenMP, która umożliwiła nam łatwe zrównoleglenie
przeszukiwania lokalnego (ten proces jest niezależny dla każdego osobnika).

\subsection{Kompilacja}
Potrzebne programy:
\begin{itemize}
  \item Kompilator obsługujący OpenMP, np. GCC 4.7
  \item CMake
\end{itemize}
Polecenia do skompilowania załączonego programu:
\begin{enumerate}
  \item \verb|tar -xvf flowshop.tar|
  \item \verb|cd flowshop/program|
  \item \verb|mkdir build|
  \item \verb|cd build|
  \item \verb|cmake .. -DCMAKE_BUILD_TYPE=Release|
  \item \verb|make|
\end{enumerate}
Jeśli kompilacja przebiegnie pomyślnie, wygenerowany zostanie program \verb|flowshop|. Po uruchomieniu
bez żadnych opcji wyświetli krótką instrukcję obsługi.




\section{Otrzymane wyniki}



\section{Wnioski}


\begin{thebibliography}{}
\bibitem{tai90} 
Éric D. Taillard. 
Some efficient heuristic methods for the flow shop sequencing problem. 
European Journal of Operational Research, 47(1):65-74, July 1990.
\end{thebibliography}


\end{document}
